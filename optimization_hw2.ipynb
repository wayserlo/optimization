{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimization_hw2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M333obaNMxH2"
      },
      "source": [
        "# Homework №2. Astanova Kamilla \n",
        "**Deadline:** 05 December, 15:59 (Moscow time).\n",
        "\n",
        "\n",
        "## General optimization problems\n",
        "\n",
        "1. Give an explicit solution of the following LP.\n",
        "\t\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& c^\\top x \\to \\min\\limits_{x \\in \\mathbb{R}^n }\\\\\n",
        "\t\\text{s.t. } &Ax = b\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "  **Решение**\n",
        "\n",
        "\tСоставим расширенную матрицу $A^*$ - матрица $A$ и дописанный справа столбец $b$. По теореме Кронекера-Капелли, система имеет решение, когда ранг ее основной матрицы равен рангу расширенной. \n",
        "\t+ Система $Ax=b$ не имеет решения $\\Leftrightarrow \\mathbf{rank}A \\neq \\mathbf{rank}A^*$. Тогда $c^\\top x$ не принимает никакое значение\n",
        "\t+ $Ax=b$ имеет единственное решение $\\Leftrightarrow \\mathbf{rank}A = \\mathbf{rank}A^* = n$. Тогда можем записать решение через псевдообратную матрицу $x=A^{-1} b$, $$c^\\top x = c^\\top A^{-1} b$$\n",
        "\t+ $Ax=b$ имеет бесконечное число решений, но вектор антиградиента $-c$ перпендикулярен множеству решений этой системы. Тогда нельзя будет пойти в сторону уменьшения функции, не выйдя при этом за пределы ограничений. А вектор $c$ будет перпендикулярен множеству решений тогда, когда если можно разложить по векторам $a_1, a_2, \\dots a_m$: $A= (a_1^\\top , a_2^\\top , \\dots a_m^\\top )$, т.е. $ \\mathbf{rank}A = \\mathbf{rank}A'$, где $A' = (a_1^\\top , a_2^\\top , \\dots a_m^\\top , c^\\top )$. В это случае значение $c^\\top x=$ (нужно как-то выразить частное решение $Ax=b$).\n",
        "\t+ $Ax=b$ имеет бесконечное число решений и при этом еще и $-c$ не перпендикулярно множеству решений, т.е. мы сможем всегда пойти в сторону антиградиента, а значит, $c^\\top x \\rightarrow -\\infty$\n",
        "\n",
        "2. Give an explicit solution of the following LP.\n",
        "\t\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& c^\\top x \\to \\min\\limits_{x \\in \\mathbb{R}^n }\\\\\n",
        "\t\\text{s.t. } & 1^\\top x = 1, \\\\\n",
        "\t& x \\succeq 0 \n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\n",
        "\tThis problem can be considered as a simplest portfolio optimization problem.\n",
        "\n",
        "  **Решение**\n",
        "\t\n",
        "\tДокажем, что точка минимума будет иметь вид $x_i=1, \\forall j \\neq i: x_j = 0$, т.е. все координаты, кроме одной, будут равны нулю. Пусть у нас есть вектор антиградиента $-c^\\top $. Он либо перпендикулярен плоскости $1^\\top x=1$ и тогда без разницы, какую точку брать, т.к. во всех точках будет одинаковое значение целевой функции. Тогда берем точку указанного типа. Либо вектор антиградиента дает какую-то проекцию на плоскость. Тогда мы пойдем вдоль этой проекции, пока не наткнемся на какую-то из границ: при этом зануляются одна или больше координат. После этого снова смотрим на проекцию, если она нулевая, то выбираем удобную точку, если нет, снова идем до границы. В конечном счете не занулится только одна координата. Определеим тогда значение целевой функции: когда мы идем в сторону антиградиента, мы идем в сторону уменьшения функции, поэтому если мы обозначим за $c'=\\min(c_1, c_2, \\dots c_n)$, то мы придем как раз в точку с ненулевой координатой, соответсвующей этому минимуму. Тогда \n",
        "\t$$\\min(c^\\top x) = \\min(c_1, c_2, \\dots c_n)\\cdot1$$\n",
        "\n",
        "3. Give an explicit solution of the following LP.\n",
        "\t\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& c^\\top x \\to \\min\\limits_{x \\in \\mathbb{R}^n }\\\\\n",
        "\t\\text{s.t. } & 1^\\top x = \\alpha, \\\\\n",
        "\t& 0 \\preceq x \\preceq 1,\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\n",
        "\twhere $\\alpha$ is an integer between $0$ and $n$. What happens if $\\alpha$ is not an integer (but satisfies $0 \\leq \\alpha \\leq n$)? What if we change the equality to an inequality $1^\\top x \\leq \\alpha$?\n",
        "\n",
        "\t**Решение**\n",
        "\n",
        "\tУпорядочим коэффициенты $c^\\top $: $c_1\\leq c_2\\leq c_3\\leq \\dots \\leq c_n$. Понятно, что нужно брать наименьшие из $c_i$ с наибольшим коэффициентом (то же самое получали и в предыдущей задаче)\n",
        "\t+ В случае, когда $\\alpha$ - целое число, то просто берем первые $\\alpha$ координат с коэффициентом $1$, а остальные положим равными $0$. Тогда \n",
        "\t$$\\min(c^\\top x) = \\sum\\limits_{i=1}^\\alpha c_i$$\n",
        "\t+ Если $\\alpha$ - нецелое, то пусть $s$ - ближайшее целое число, меньшее $\\alpha$, тогда \n",
        "\t$$ \\min(c^\\top x) = \\sum\\limits_{i=1}^s c_i + (\\alpha-s)\\cdot c_{s+1}$$ \n",
        "\t+ Если $1^\\top x\\leq \\alpha$, то тут можно учесть, что если в первом случае с какого-то $i$ в сумме могли появляться и положительные $c_i$ (чтобы выполнялось равенство $1^\\top x = \\alpha$), то теперь мы можем взять только отрицательные (но то же самое, если $c_i < 0$ будет много, то получится взять не все, из-за ограничения $1^\\top x \\leq \\alpha$). Тогда общий ответ можно выразить как (считаем $\\alpha$ целым)\n",
        "\t$$\\min(c^\\top x) = \\sum\\limits_{i=1}^\\alpha \\min(c_i, 0)$$ \n",
        "\n",
        "\n",
        "4. Give an explicit solution of the following QP.\n",
        "\t\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& c^\\top x \\to \\min\\limits_{x \\in \\mathbb{R}^n }\\\\\n",
        "\t\\text{s.t. } & x^\\top A x \\leq 1,\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\n",
        "\twhere $A \\in \\mathbb{S}^n_{++}, c \\neq 0$. What is the solution if the problem is not convex $(A \\notin \\mathbb{S}^n_{++})$ (Hint: consider eigendecomposition of the matrix: $A = Q \\mathbf{diag}(\\lambda)Q^\\top = \\sum\\limits_{i=1}^n \\lambda_i q_i q_i^\\top$ and different cases of $\\lambda >0, \\lambda=0, \\lambda<0$)?\n",
        "\n",
        "\t**Решение**\n",
        "\n",
        "\t + Так как $f_0(x) = c^\\top x$ и $f_1 = x^\\top A x -1, A\\in\\mathbb{S}^n_{++}$ выпуклые, так же выполнено условие Слейтера (например, для $x=0: 0^\\top A0 = 0<1$), то условия из ККТ будут достаточными и необходимыми. Распишем\n",
        "\t$$ L(x,\\alpha) = c^\\top x + \\alpha^*(x^\\top A x -1)$$\n",
        "\tТогда\n",
        "\t$$\\begin{cases}\n",
        "\t\\nabla_x L(x^*, \\alpha^*) = с + \\alpha(A+A^\\top)x^* = 0\\\\\n",
        "\t\\alpha^*\\geq 0\\\\ \n",
        "\t\\alpha((x^*)^\\top Ax^*-1)=0\\\\ \n",
        "\t(x^*)^\\top Ax^*-1 \\leq0\n",
        "\t\\end{cases} $$\n",
        "Если вдруг $\\alpha^* =0$, то из первого равенства $c+0=0$, но у нас в условии сказано, что $c\\neq0$, поэтому $\\alpha^*>0\\Rightarrow (x^*)^\\top Ax^*-1=0$. Тогда система перепишется (с учетом, что $A \\in \\mathbb{S}^n$):\n",
        "\t$$\\begin{cases}\n",
        "\tс + 2\\alpha^*Ax^* = 0\\\\\n",
        "\t\\alpha^*> 0\\\\ \n",
        "\t(x^*)^\\top Ax^*=1\n",
        "\t\\end{cases} $$\n",
        "Из первого выражаем $x^*$\n",
        "$$ x^* = -\\dfrac{1}{2\\alpha^*}A^{-1}c$$\n",
        "Подставляем в третье, преобразовываем и выражаем $\\alpha^*$:\n",
        "$$ \\dfrac{1}{4(\\alpha^*)^2}c^\\top A^{-\\top}AA^{-1}c=1$$\n",
        "$$ \\dfrac{1}{4(\\alpha^*)^2}c^\\top A^{-1}c=1$$\n",
        "$$ \\alpha^* = \\dfrac{1}{2}\\left(c^\\top A^{-1}c\\right)^{\\frac{1}{2}}$$\n",
        "Тогда \n",
        "$$ c^\\top x^* = - \\dfrac{1}{2\\alpha^*}c^\\top A^{-1}c = - \\left(c^\\top A^{-1}c\\right)^{\\frac{1}{2}}$$\n",
        "+ Добавим дополнительное условие. Как я понимаю, мы все еще можем считать, что $A\\in \\mathbb{S}^n$. $A = Q \\mathbf{diag}(\\lambda)Q^\\top$, где $Q$ формируется из собственных векторов и $Q^{-1}=Q^\\top$ как раз из-за симметричности. Тогда введем новые переменные\n",
        "\t$$ \\begin{cases}\n",
        "\ty=Qx\\\\ \n",
        "\tf=Qc\n",
        "\t\\end{cases}$$\n",
        "\tИ перепишем\n",
        "\t$$f^\\top y = c^\\top Q^\\top Qx = c^\\top x$$\n",
        "\t$$ x^\\top A x = $$\n",
        "\n",
        "5. Give an explicit solution of the following QP.\n",
        "\t\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& c^\\top x \\to \\min\\limits_{x \\in \\mathbb{R}^n }\\\\\n",
        "\t\\text{s.t. } & (x - x_c)^\\top A (x - x_c) \\leq 1,\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\n",
        "\twhere $A \\in \\mathbb{S}^n_{++}, c \\neq 0, x_c \\in \\mathbb{R}^n$. \n",
        "\n",
        "\t**Решение**\n",
        "\n",
        "\tЗаметим, что $f_0(x)=c^\\top x$ аффинная, а значит, выпуклая. $f_1(x) = (x - x_c)^\\top A (x - x_c) - 1$ выпуклая, т.к. $\\in \\mathbb{S}^n_{++}$, так же выполнено условие Слейтера (например, для $x=x_c: 0^\\top A0 = 0<1$)  поэтому условия ККТ будут необходимыми и достаточными. Составим тогда функцию Лагранжа и распишем ККТ (я толькоо тут звездочки в ККТ буду опусать, потому что неудобно их писать):\n",
        "\t$$ L(x, \\lambda) = c^\\top x + \\lambda((x - x_c)^\\top A (x - x_c) - 1)$$\n",
        "\t$$\\begin{cases}\n",
        "\t\\nabla_x L(x, \\lambda) = c + 2\\lambda A(x-x_c)=0\\\\\n",
        "\t\\lambda \\geq 0\\\\\n",
        "\t\\lambda((x - x_c)^\\top A (x - x_c) - 1) =0\\\\ \n",
        "\t(x - x_c)^\\top A (x - x_c) - 1\\leq 0\n",
        "\t\\end{cases}$$\n",
        "\tПри этом т.к. $c\\neq0$, то и $\\lambda>0$, т.е. остается:\n",
        "\t$$\\begin{cases}\n",
        "\tx-x_c = -\\dfrac{1}{2\\lambda}A^{-1}c\\\\\n",
        "\t\\lambda >0 \\\\\n",
        "\t(x - x_c)^\\top A (x - x_c) =1\\\\ \n",
        "\t\\end{cases}$$\n",
        "\t$$\\begin{cases}\n",
        "\tx-x_c = -\\dfrac{1}{2\\lambda}A^{-1}c \\\\\n",
        "\t\\dfrac{1}{4\\lambda^2}c^\\top A^{-\\top}AA^{-1}c=1 \\\\\n",
        "\t\\lambda >0\n",
        "\t\\end{cases}$$\n",
        "\t$$ \\lambda = \\dfrac{1}{2}\\left(c^\\top A^{-1}c\\right)^{\\frac{1}{2}}\\Rightarrow$$\n",
        "\t$$ c^\\top (x-x_c) = - \\left(c^\\top A^{-1}c\\right)^{\\frac{1}{2}}$$\n",
        "\t$$ c^\\top x = c^\\top x_c - \\left(c^\\top A^{-1}c\\right)^{\\frac{1}{2}}$$\n",
        "6. Give an explicit solution of the following QP.\n",
        "\t\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& x^\\top Bx \\to \\min\\limits_{x \\in \\mathbb{R}^n }\\\\\n",
        "\t\\text{s.t. } & x^\\top A x \\leq 1,\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\n",
        "\twhere $A \\in \\mathbb{S}^n_{++}, B \\in \\mathbb{S}^n_{+}$.\n",
        "\t\n",
        "\t**Решение**\n",
        "\n",
        "\tАналогично, $f_0(x) = x^\\top Bx$ и $f_1(x)= x^\\top A x-1$, выпуклые за счет того, что $A \\in \\mathbb{S}^n_{++}, B \\in \\mathbb{S}^n_{+}$, так же выполнено условие Слейтера (например, для $x=0: 0^\\top A0 = 0<1$) тогда ККТ достаточные и необходимые\n",
        "\t$$ L(x, \\lambda) = x^\\top Bx + \\lambda (x^\\top A x-1)$$\n",
        "\t$$ \\begin{cases}\n",
        "\t\\nabla_x L = 2Bx + 2\\lambda Ax=0\\\\\n",
        "\t\\lambda\\geq 0\\\\\n",
        "\t\\lambda(x^\\top A x-1)=0\\\\\n",
        "\tx^\\top A x-1\\leq0\n",
        "\t\\end{cases}$$\n",
        "\tТеперь заметим, что т.к. $B\\in \\mathbb{S}^n_{+}$, то по определению $\\forall x: x^\\top B x \\geq 0$. Минимально возможное значение, которое мы можем достигнуть равно 0. И достигнуть его мы можем при $x=0$. Можем подставить его в записанную систему и получим, что это оптимальная точка (при этом $\\lambda = 0$). Т.е. \n",
        "\t$$ x^\\top Bx =0$$\n",
        "\n",
        "7.  Consider the equality constrained least-squares problem\n",
        "\t\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& \\|Ax - b\\|_2^2 \\to \\min\\limits_{x \\in \\mathbb{R}^n }\\\\\n",
        "\t\\text{s.t. } & Cx = d,\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\n",
        "\twhere $A \\in \\mathbb{R}^{m \\times n}$ with $\\mathbf{rank }A = n$, and $C \\in \\mathbb{R}^{k \\times n}$ with $\\mathbf{rank }C = k$. Give the KKT conditions, and derive expressions for the primal solution $x^*$ and the dual solution $\\lambda^*$.\n",
        "\n",
        "\t**Решение**\n",
        "\n",
        "\t$$ L(x, \\lambda) = \\|Ax - b\\|_2^2 + \\lambda^\\top(Cx - d)$$\n",
        "\tТут, $f_0(x) = \\|Ax - b\\|_2^2$ - выпуклая (на семинаре рассматривали функцию норма х), $h(x) = Cx - d$, аффинная и если ранг матрицы $\\mathbf{rank }(C|d)=k$, то система разрешима и можно найт $x=\\mathbf{sol}(Cx=d)$, т.е. будет выполнено условие Слейтера, поэтому ККТ необходимы и достаточны\n",
        "\t$$\\begin{cases}\n",
        "\t\\nabla_x L = 2A^\\top (Ax-b)+ C^\\top\\lambda=0\\\\\n",
        "\t\\nabla_\\lambda L = Cx-d=0\n",
        "\t\\end{cases}$$\n",
        "\tЕсли $A^\\top A$ обратима, то из первого получаем\n",
        "\t$$x = \\dfrac{1}{2}(A^\\top A)^{-1} (2A^\\top b - C^\\top \\lambda) $$\n",
        "\tПодставляем во второе и находим $\\lambda$\n",
        "\t$$ \\dfrac{1}{2}C(A^\\top A)^{-1} (2A^\\top b - C^\\top \\lambda) = d$$\n",
        "\t$$ \\lambda = 2(AC^{-1})^\\top (b-AC^{-1})d) $$\n",
        "\tИ обратно подставляем в $x$\n",
        "\t$$ x = C^{-1}d $$\n",
        "\tДа уж, вышло как-то странно, мб тут матрицы не так обращаются\n",
        "\n",
        "8. Derive the KKT conditions for the problem\n",
        "\t\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& \\mathbf{tr \\;}X - \\log\\text{det }X \\to \\min\\limits_{X \\in \\mathbb{S}^n_{++} }\\\\\n",
        "\t\\text{s.t. } & Xs = y,\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\n",
        "\twhere $y \\in \\mathbb{R}^n$ and $s \\in \\mathbb{R}^n$ are given with $y^\\top s = 1$. Verify that the optimal solution is given by\n",
        "\n",
        "\t$$\n",
        "\tX^* = I + yy^\\top - \\dfrac{1}{s^\\top s}ss^\\top\n",
        "\t$$\n",
        "\t**Решение**\n",
        "\n",
        "\tЛагранжиан и ККТ\n",
        "\t$$ L(x, \\lambda) = \\mathbf{tr \\;}X - \\log\\text{det }X + \\lambda^\\top (Xs-y)$$\n",
        "\t$$\\begin{cases}\n",
        "\t\\nabla_x L = I - X^{-1} +\\lambda s^\\top=0\\\\\n",
        "\t\\nabla_\\lambda L = Xs-y=0\n",
        "\t\\end{cases}$$\n",
        "\tИз первого найдем $X^{-1}$ и подставим потом в выражение для $s$, полученное из второго\n",
        "\t$$ X^{-1} = I + \\lambda s^\\top = I + \\dfrac{1}{2}(\\lambda s^\\top+ s \\lambda^\\top)\\hspace{1cm}(1)$$\n",
        "\t$$ s = X^{-1} y = y +\\dfrac{1}{2}(\\lambda\\cdot1+(\\lambda^\\top y)s) \\hspace{1.5cm}(2)$$\n",
        "\tиз последнего выразим $s-y$ и рассмотрим скалярное произведение $ (s-y)^\\top y$\n",
        "\t$$s-y = \\dfrac{1}{2}(\\lambda+(\\lambda^\\top y)s)$$\n",
        "\t$$ (s-y)^\\top y = \\dfrac{1}{2}(\\lambda^\\top y +(\\lambda^\\top y) \\cdot 1) = \\lambda^\\top y$$\n",
        "\tт.е. мы получили $\\lambda = s-y$, откуда $ s= \\lambda + y$\n",
        "\t $$ 1 = s^\\top y = \\lambda^\\top y + y^\\top y \\Rightarrow \\lambda^\\top y = 1 - y^\\top y$$\n",
        "\t теперь $\\lambda^\\top y$ подставим в $(2)$\n",
        "\t $$s = y + \\dfrac{1}{2}(\\lambda +s - (y^\\top y )s)\\Rightarrow$$\n",
        "\t $$ \\lambda = (1+y^\\top y)s -2y$$\n",
        "\t И это подставим в $(1)$\n",
        "\t $$ X^{-1} = I + \\dfrac{1}{2}((ss^\\top + y^\\top y ss^\\top)\\cdot2 -2ys^\\top-2sy^\\top)= $$\n",
        "\t $$=I + (1+y^\\top y)ss^\\top -ys^\\top-sy^\\top$$\n",
        "\t Теперь, если указанный $X^*$ - оптимальное решение, то $X^{-1}X^* = I$, проверим это, перемножив обе матрицы\n",
        "\t $$ X^{-1}X^* = (I + (1+y^\\top y)ss^\\top -ys^\\top-sy^\\top)(I + yy^\\top - \\dfrac{1}{s^\\top s}ss^\\top)=$$\n",
        "\t $$=I + yy^\\top - \\dfrac{1}{s^\\top s}ss^\\top +  (1+y^\\top y)(ss^\\top +sy^\\top - ss^\\top) - ys^T -yy^\\top +ys^\\top $$\n",
        "\t $$ - sy^\\top -(y^\\top y)sy^\\top +\\dfrac{1}{s^\\top s}ss^\\top = I$$\n",
        "\t Ура, все сошлось, т.е. $X^*$ действительно оптимальное решение\n",
        "\n",
        "9.  **Supporting hyperplane interpretation of KKT conditions**. Consider a **convex** problem with no equality constraints\n",
        "\t\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& f_0(x) \\to \\min\\limits_{x \\in \\mathbb{R}^n }\\\\\n",
        "\t\\text{s.t. } & f_i(x) \\leq 0, \\quad i = [1,m]\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\n",
        "\tAssume, that $\\exists x^* \\in \\mathbb{R}^n, \\mu^* \\in \\mathbb{R}^m$ satisfy the KKT conditions\n",
        "\t\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "    & \\nabla_x L (x^*, \\mu^*) = \\nabla f_0(x^*) + \\sum\\limits_{i=1}^m\\mu_i^*\\nabla f_i(x^*) = 0 \\\\\n",
        "    & \\mu^*_i \\geq 0, \\quad i = [1,m] \\\\\n",
        "    & \\mu^*_i f_i(x^*) = 0, \\quad i = [1,m]\\\\\n",
        "    & f_i(x^*) \\leq 0, \\quad i = [1,m]\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\n",
        "\tShow that\n",
        "\n",
        "\t$$\n",
        "\t\\nabla f_0(x^*)^\\top (x - x^*) \\geq 0\n",
        "\t$$\n",
        "\n",
        "\tfor all feasible $x$. In other words the KKT conditions imply the simple optimality criterion or $\\nabla f_0(x^*)$ defines a supporting hyperplane to the feasible set at $x^*$\n",
        "\n",
        "\t**Решение**\n",
        "\n",
        "\tИз первого условия ККТ\n",
        "\t$$\\nabla f_0(x^*)^\\top = - \\sum\\limits_{i=1}^m\\mu_i^*\\nabla f_i(x^*)$$\n",
        "\tВ силу выпуклости функции $f_i(x)$\n",
        "\t$$f_i(x) \\geq f_i(x^*) + \\nabla f_i^\\top(x^*)(x-x^*)$$\n",
        "\tТеперь, если мы умножаем на $\\mu_i^*\\geq 0$, то знак неравенства не изменится, поэтому можем умножить на $\\mu_i^*$ и просуммировать\n",
        "\t$$ 0\\geq \\sum\\limits_{i=1}^m\\mu_i^* f_i(x)\\geq \\sum\\limits_{i=1}^m\\mu_i^* f_i(x^*)+ \\sum\\limits_{i=1}^m\\mu_i^*\\nabla f_i(x^*)(x-x^*)$$\n",
        "\tЕсли $x$ из допустимого множества, то $f_i(x)\\leq0$, поэтому слева еще неравенство с 0. С учетом третьего условия ККТ получаем\n",
        "\t$$ 0 \\geq 0 + \\sum\\limits_{i=1}^m\\mu_i^*\\nabla f_i(x^*)(x-x^*) =-\\nabla f_0(x^*)^\\top (x - x^*) $$\n",
        "\tОткуда и получаем требуемоего неравенство\n",
        "\t$$ \\nabla f_0(x^*)^\\top (x - x^*) \\geq 0$$\n",
        "\n",
        "## Duality\n",
        "\n",
        "1.  **Fenchel + Lagrange = ♥.** Express the dual problem of\n",
        "\t\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& c^\\top x\\to \\min\\limits_{x \\in \\mathbb{R}^n }\\\\\n",
        "\t\\text{s.t. } & f(x) \\leq 0\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\n",
        "\twith $c \\neq 0$, in terms of the conjugate function $f^*$. Explain why the problem you give is convex. We do not assume $f$ is convex.\n",
        "\n",
        "\t**Решение**\n",
        "\n",
        "\tЗнаем, что (еще на семинаре разбирали такое)\n",
        "\t$$ \\inf f(x) = -\\sup (-f(x))$$\n",
        "\tПоэтому, если у нас функция Лагранжа для данной задачи\n",
        "\t$$ L(x, \\lambda) = c^\\top x +\\lambda f(x)$$\n",
        "\tто двойственная задача\n",
        "\t$$g(\\lambda) = \\inf\\limits_{x\\in\\mathbb{R}^n}L(x, \\lambda) = \\inf\\limits_{x\\in\\mathbb{R}^n}(c^\\top x +\\lambda f(x))= $$\n",
        "\t$$ =-\\sup\\limits_{x\\in\\mathbb{R}^n}(-c^\\top x - \\lambda f(x)) = \\sup\\limits_{x\\in\\mathbb{R}^n}(c^\\top x -\\lambda f(-x))$$\n",
        "\tДополнительно будем полагать, что $\\lambda >0$ (в случае, если $\\lambda = 0$, то $c^\\top x \\to -\\infty$). Тогда $\\sup \\lambda f(x) = \\lambda sup f(x)$\n",
        "\t$$ g(\\lambda) = -\\lambda \\sup\\limits_{x\\in\\mathbb{R}^n}\\left(-\\frac{1}{\\lambda}c^\\top x - f(x)\\right) = -\\lambda f^*\\left(-\\frac{1}{\\lambda}c\\right) $$\n",
        "\tПоэтому dual problem можно сформулировать как\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& -\\lambda f^*\\left(-\\frac{1}{\\lambda}c\\right)\\to \\max\\limits_{x \\in \\mathbb{R}^n }\\\\\n",
        "\t\\text{s.t. } & \\lambda \\geq 0\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\n",
        "2. **Minimum volume covering ellipsoid.** Let we have the primal problem:\n",
        "\t\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& \\ln \\text{det} X^{-1} \\to \\min\\limits_{X \\in \\mathbb{S}^{n}_{++} }\\\\\n",
        "\t\\text{s.t. } & a_i^\\top X a_i \\leq 1 , i = 1, \\ldots, m\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\n",
        "\t1. Find Lagrangian of the primal problem\n",
        "\t1. Find the dual function\n",
        "\t1. Write down the dual problem\n",
        "\t1. Check whether problem holds strong duality or not\n",
        "\t1. Write down the solution of the dual problem\n",
        "\n",
        "\t**Решение**\n",
        "\tИнтерпретация проблемы: найти минимальный эллисоид $\\varepsilon_X$\n",
        "\t$$ \\varepsilon_X = \\{z| z^\\top Xz\\leq 1\\}$$\n",
        "\tтакой, что $\\forall i: a_i\\in varepsilon_X$\n",
        "\n",
        "\tЭти ограниченя можно переписать в виде\n",
        "\t$$ \\textbf{tr}((a_ia_i^\\top)X)\\leq1$$\n",
        "\t1. $$L(x, \\lambda) = \\ln \\det X^{-1} + \\sum\\limits_{i=1}^m\\lambda_i (a_i^\\top X a_i-1)$$\n",
        "\t2. В Бойде была приведена сопряженная для $f_0$, поэтому сразу без вывода\n",
        "\t$$ f_0^*(Y) = \\ln \\det (-Y)^{-1}-1, Y\\in -S^n_{++}$$\n",
        "\tТак же в Бойде был приведен следующий результат для задачи\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& f_0(x) \\to \\min\\\\\n",
        "\t\\text{s.t. } & Ax \\preceq b\\\\ \n",
        "\t& Cx=d\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\t$$g(\\lambda, \\nu) = -b^\\top \\lambda - d^\\top \\nu - f^*_0(-A^\\top\\lambda-C^\\top\\nu) $$\n",
        "\tПоэтому в нашем случае\n",
        "\t$$g(\\lambda) = \\begin{cases}\n",
        "\t\\ln \\det\\left(\\sum\\limits_{i=1}^m\\lambda_ia_ia_i^\\top\\right)-1^\\top\\lambda+n, & \\sum\\limits_{i=1}^m\\lambda_ia_ia_i^\\top\\succ 0\\\\ \n",
        "\t-\\infty, &otherwise\n",
        "\t\\end{cases} $$\n",
        "\t3. Dual\n",
        "\t$$ \\begin{split}\n",
        "\t\\ln \\det\\left(\\sum\\limits_{i=1}^m\\lambda_ia_ia_i^\\top\\right)-1^\\top\\lambda+n \\to \\max\\limits_{\\sum\\limits_{i=1}^m\\lambda_ia_ia_i^\\top\\succ 0}\\\\ \n",
        "\t\\text{s.t. }  \\lambda\\succeq0\n",
        "\t\\end{split}$$\n",
        "\t4. Это задача выпуклой оптимизации и существует нулевая матрица $X=O$, для которой ограничения типа неравенства выполнены строго, поэтому условия Слейтера выполнены\n",
        "\t5. \n",
        "\t\n",
        "3. **A penalty method for equality constraints.** We consider the problem of minimization\n",
        "\t$$\n",
        "\t\\begin{split}\n",
        "\t& f_0(x) \\to \\min\\limits_{x \\in \\mathbb{R}^{n} }\\\\\n",
        "\t\\text{s.t. } & Ax = b,\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\t\n",
        "\twhere $f_0(x): \\mathbb{R}^n \\to\\mathbb{R} $ is convex and differentiable, and $\\alpha \\in \\mathbb{R}^{m \\times n}$ with $\\mathbf{rank }A = m$. In a quadratic penalty method, we form an auxiliary function\n",
        "\n",
        "\t$$\n",
        "\t\\phi(x) = f_0(x) + \\alpha \\|Ax - b\\|_2^2,\n",
        "\t$$\n",
        "\t\n",
        "\twhere $\\alpha > 0$ is a parameter. This auxiliary function consists of the objective plus the penalty term $\\alpha \\|Ax - b\\|_2^2$. The idea is that a minimizer of the auxiliary function, $\\tilde{x}$, should be an approximate solution of the original problem. Intuition suggests that the larger the penalty weight $\\alpha$, the better the approximation $\\tilde{x}$ to a solution of the original problem. Suppose $\\tilde{x}$ is a minimizer of $\\phi(x)$. Show how to find, from $\\tilde{x}$, a dual feasible point for the original problem. Find the corresponding lower bound on the optimal value of the original problem.\n",
        "\n",
        "\t**Решение**\n",
        "\n",
        "\tАппроксимируем, вводя штрафные функции. Посмотрим тогда сначала на $\\nabla\\phi(\\tilde{x})=0$ (т.к. $\\tilde{x}$ минимизирует)\n",
        "\t$$\\nabla\\phi(\\tilde{x}) = \\nabla f_0(\\tilde{x}) + 2\\alpha A^\\top (A\\tilde{x}-b) = 0$$\n",
        "\tЕсли обозначим $\\lambda = \\alpha(A\\tilde{x}-b)$ и рассмотрим \n",
        "\t$$ L(x,2\\lambda) = f_0(x) + 2\\alpha (A\\tilde{x}-b)^\\top(Ax-b)$$\n",
        "\tто $$\\nabla_x L(\\tilde{x}, 2\\alpha) = \\nabla f_0(\\tilde{x}) + 2\\alpha A^\\top (A\\tilde{x}-b) =\\nabla\\phi(\\tilde{x})= 0$$\n",
        "\tт.е. минимизируется функция Лагранжа в $\\tilde{x}$. Из dual problem\n",
        "\t$$ \\inf L(x,2\\lambda) = f_0(\\tilde{x}) + 2\\alpha(A\\tilde{x}-b)^\\top(A\\tilde{x}-b) = $$\n",
        "\t$$=f_0(\\tilde{x}) + \\alpha \\|A\\tilde{x} - b\\|_2^2$$\n",
        "\tПоэтому $$ f_0(x) \\geq f_0(\\tilde{x}) + \\alpha \\|A\\tilde{x} - b\\|_2^2$$\n",
        "\n",
        "4. **Analytic centering.** Derive a dual problem for\n",
        "\t\n",
        "\t$$\n",
        "\t-\\sum_{i=1}^m \\log (b_i - a_i^\\top x) \\to \\min\\limits_{x \\in \\mathbb{R}^{n} }\n",
        "\t$$\n",
        "\n",
        "\twith domain $\\{x \\mid a^\\top_i x < b_i , i = [1,m]\\}$. \n",
        "\t\n",
        "\tFirst introduce new variables $y_i$ and equality constraints $y_i = b_i − a^\\top_i x$. (The solution of this problem is called the analytic center of the linear inequalities $a^\\top_i x \\leq b_i ,i = [1,m]$.  Analytic centers have geometric applications, and play an important role in barrier methods.) \n",
        "\n",
        "\t**Решение**\n",
        "\tПерепишем с новыми переменными $y_i = b_i - a_i^\\top x$\n",
        "\t$$\\begin{split}\n",
        "\t&-\\sum_{i=1}^m \\log (y_i) \\to \\min\\limits_{x \\in \\mathbb{R}^{n} }\\\\\n",
        "\t\\text{s.t. }&y_i = b_i - a_i^\\top x\n",
        "\t\\end{split}\n",
        "\t$$\n",
        "\tтолько $\\textbf{dom}f_0 = \\{y_i| y_i>0\\}$.\n",
        "\tЕсли положить $A=(a_1^\\top, \\ldots, a_m\\top)$, то ограничения можно переписать как $Ax\\prec b$, и они полностью определеяются $\\textbf{dom}f_0 = \\{x|Ax\\prec b\\}$.\n",
        "\n",
        "\tНеобходимые и достаточные условия при этом можно записать как\n",
        "\t$$ \\begin{cases}\n",
        "\t\\nabla f_0(x) = \\sum_{i=1}^m \\dfrac{1}{b_i - a_i^\\top x}a_i = 0\\\\\n",
        "\tAx\\prec b\n",
        "\t\\end{cases}$$\n",
        "\t Тогда\n",
        "\t + Решение системы отсутсвует, если множество $f_0$ неограничен снизу\n",
        "\t + Решений бесконечно много и они образуют аффинное множество (в качестве минимума возьмем любое частное)\n",
        "\t + Решение единственно и оно является минимумом\n",
        "\n",
        "## Applications\n",
        "\n",
        "1. **📱🎧💻 Covers manufacturing.** Random Corp is producing covers for following products: \n",
        "\t* 📱 phones\n",
        "\t* 🎧 headphones\n",
        "\t* 💻 laptops\n",
        "\n",
        "\tThe company’s production facilities are such that if we devote the entire production to headphones covers, we can produce $6000$ of them in one day. If we devote the entire production to phone covers or laptop covers, we can produce $5000$ or $3000$ of them in one day. \n",
        "\n",
        "\tThe production schedule is one week ($5$ working days), and the week’s production must be stored before distribution. Storing $1000$ headphones covers (packaging included) takes up $50$ cubic feet of space. Storing $1000$ phone covers (packaging included) takes up $60$ cubic feet of space, and storing $1000$ laptop covers (packaging included) takes up $220$ cubic feet of space. The total storage space available is $6000$ cubic feet. \n",
        "\n",
        "\tDue to commercial agreements with Random Corp has to deliver at least $5000$ headphones covers and $4000$ laptop covers per week in order to strengthen the product’s diffusion. \n",
        "\n",
        "\tThe marketing department estimates that the weekly demand for headphones covers, phone, and laptop covers does not exceed $10000$ and $15000$, and $8000$ units, therefore the company does not want to produce more than these amounts for headphones, phone, and laptop covers. \n",
        "\n",
        "\tFinally, the net profit per each headphones cover, phone cover, and laptop cover is $\\$5$, $\\$7$, and $\\$12$, respectively.\n",
        "\n",
        "\tThe aim is to determine a weekly production schedule that maximizes the total net profit.\n",
        "\n",
        "\tWrite a correct Linear Programming formulation for the problem.\tUse following variables:\n",
        "\n",
        "\t* $y_1$ = number of headphones covers produced over the week,  \n",
        "\t* $y_2$ = number of phone covers produced over the week,  \n",
        "\t* $y_3$ = number of laptop covers produced over the week.  \n",
        "\n",
        "\tFind the solution to the problem using `PyOMO.` Take a look at the example , described in the class [🐍 code](https://colab.research.google.com/github/MerkulovDaniil/sber219/blob/main/notebooks/8_01.ipynb){: .btn}.\n",
        "\n",
        "\t```python\n",
        "\t!pip install pyomo --quiet\n",
        "\t! sudo apt-get install glpk-utils --quiet  # GLPK\n",
        "\t! sudo apt-get install coinor-cbc --quiet  # CoinOR\n",
        "\t```\n",
        "\n",
        "2. **📼 Optimal watching TED talks** In this task you are to formulate LP problem for selecting TED talks for watching. Take a look at the example , described in the class  [🐍 code](https://colab.research.google.com/github/MerkulovDaniil/sber219/blob/main/notebooks/8_1.ipynb){: .btn}.\n",
        "\t\n",
        "\t```python\n",
        "\t!pip install pulp\n",
        "\t\n",
        "\t# Commented out IPython magic to ensure Python compatibility.\n",
        "\t# %matplotlib inline\n",
        "\t \n",
        "\timport pulp\n",
        "\timport numpy as np\n",
        "\timport pandas as pd\n",
        "\timport re\n",
        "\timport matplotlib.pyplot as plt\n",
        "\tfrom IPython.display import Image\n",
        "\t\n",
        "\t# Download the dataset\n",
        "\t\n",
        "\t# Read the dataset into pandas dataframe, convert duration from seconds to minutes\n",
        "\tted = pd.read_csv('https://raw.githubusercontent.com/MerkulovDaniil/optim/master/assets/Notebooks/ted_main.csv', encoding='ISO-8859-1')\n",
        "\tted['duration'] = ted['duration'] / 60\n",
        "\tted = ted.round({'duration': 1})\n",
        "\t\n",
        "\t# Select subset of columns & rows (if required)\n",
        "\t# data = ted.sample(n=1000) # 'n' can be changed as required\n",
        "\tdata = ted\n",
        "\tselected_cols = ['name', 'event', 'duration', 'views']\n",
        "\tdata.reset_index(inplace=True)\n",
        "\tdata.head()\n",
        "\t\n",
        "\t# create LP object,\n",
        "\t# set up as a maximization problem --> since we want to maximize the number of TED talks to watch\n",
        "\tprob = pulp.LpProblem('WatchingTEDTalks', pulp.LpMaximize)\n",
        "\t\n",
        "\t# create decision - yes or no to watch the talk?\n",
        "\tdecision_variables = []\n",
        "\tfor rownum, row in data.iterrows():\n",
        "\t    variable = str('x' + str(row['index']))\n",
        "\t    variable = pulp.LpVariable(str(variable), lowBound = 0, upBound = 1) # make variable binary\n",
        "\t    decision_variables.append(variable)\n",
        "\t    \n",
        "\tprint('Total number of decision variables: ' + str(len(decision_variables)))\n",
        "\t\n",
        "\t###\n",
        "\t### YOUR CODE HERE\n",
        "\t###\n",
        "\t\n",
        "\t\n",
        "\t# Be careful, the output will be huge\n",
        "\t# print(prob)\n",
        "\tprob.writeLP('WatchingTEDTalks.lp')\n",
        "\tprint('🤔 The problem has successfully formulated')\n",
        "\t\n",
        "\toptimization_result = prob.solve()\n",
        "\t\n",
        "\tassert optimization_result == pulp.LpStatusOptimal\n",
        "\tprint('Status:', pulp.LpStatus[prob.status])\n",
        "\tprint('Optimal Solution to the problem: ', pulp.value(prob.objective))\n",
        "\tprint('Individual decision variables: ')\n",
        "\t\n",
        "\tfor v in prob.variables():\n",
        "\t    if v.varValue > 0:\n",
        "\t        print(v.name, '=', v.varValue)\n",
        "\t\n",
        "\t# reorder results\n",
        "\tvariable_name = []\n",
        "\tvariable_value = []\n",
        "\t\n",
        "\tfor v in prob.variables():\n",
        "\t    variable_name.append(v.name)\n",
        "\t    variable_value.append(v.varValue)\n",
        "\t    \n",
        "\tdf = pd.DataFrame({'index': variable_name, 'value': variable_value})\n",
        "\tfor rownum, row in df.iterrows():\n",
        "\t    value = re.findall(r'(\\d+)', row['index'])\n",
        "\t    df.loc[rownum, 'index'] = int(value[0])\n",
        "\t    \n",
        "\t# df = df.sort_index(by = 'index')\n",
        "\tdf = df.sort_values(by = 'index')\n",
        "\tresult = pd.merge(data, df, on = 'index')\n",
        "\tresult = result[result['value'] == 1].sort_values(by = 'views', ascending = False)\n",
        "\tselected_cols_final = ['name', 'event', 'duration', 'views']\n",
        "\tfinal_set_of_talks_to_watch = result[selected_cols_final]\n",
        "\t\n",
        "\tfrom IPython.display import display, HTML\n",
        "\tdisplay(HTML(final_set_of_talks_to_watch.to_html(index=False)))\n",
        "\t```\n",
        "\n",
        "\t1. Your task is to choose linear objective function and justify your choice. \n",
        "\t1. Then select at least $3$ various non-trivial linear constraints on the solution. (For example, bound the average length of the selected videos or etc.)\n",
        "\t1. Solve the problem with `pulp` library using code above.\n",
        "\n",
        "3. **Risk budget allocation.** [source](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook_extra_exercises.pdf). Suppose an amount $$x_i>0$$ is invested in $$n$$ assets, labeled $$i=1,..., n$$, with asset return covariance matrix $$\\Sigma \\in \\mathcal{S}_{++}^n$$. We define the *risk* of the investments as the standard deviation of the total return, $$R(x) = (x^\\top\\Sigma x)^{1/2}$$.\n",
        "\n",
        "\tWe define the (relative) *risk contribution* of asset $$i$$ (in the portfolio $$x$$) as\n",
        "\n",
        "\t$$\n",
        "\t\\rho_i = \\frac{\\partial \\log R(x)}{\\partial \\log x_i} = \\frac{\\partial R(x)}{R(x)} \\frac{x_i}{\\partial x_i}, \\quad i=1, \\ldots, n.\n",
        "\t$$\n",
        "\n",
        "\tWhy is the logarithm here?! Because it reflects fraction of relative changex (say, per 1%). Take a look at [easticity definition at wiki](https://en.wikipedia.org/wiki/Elasticity_(economics)). Thus $$\\rho_i$$ gives the fractional increase in risk per fractional increase\n",
        "\tin investment $$i$$. We can express the risk contributions as\n",
        "\n",
        "\t$$\n",
        "\t\\rho_i = \\frac{x_i (\\Sigma x)_i} {x^\\top\\Sigma x}, \\quad i=1, \\ldots, n,\n",
        "\t$$\n",
        "\n",
        "\tfrom which we see that $\\sum_{i=1}^n \\rho_i = 1$. For general $x$, we can have $\\rho_i <0$, which means that a small increase in investment $i$ decreases the risk. Desirable investment choices have $\\rho_i>0$, in which case we can interpret $\\rho_i$ as the fraction of the total risk contributed by the investment in asset $i$. Note that the risk contributions are homogeneous, i.e., scaling $x$ by a positive constant does not affect $\\rho_i$.\n",
        "\n",
        "\t**Problem statement**\n",
        "\n",
        "\tIn the *risk budget allocation problem*, we are given $\\Sigma$ and a set of desired risk contributions $\\rho_i^\\mathrm{des}>0$ with $\\bf{1}^\\top \\rho^\\mathrm{des}=1$; the goal is to find an investment mix $x\\succ 0$, $\\bf{1}^\\top x =1$, with these risk contributions.\n",
        "\n",
        "\tWhen $\\rho^\\mathrm{des} = (1/n)\\bf{1}$, the problem is to find an investment mix that achieves so-called *risk parity*.\n",
        "\n",
        "\t1. Explain how to solve the risk budget allocation problem using convex optimization.\n",
        "\n",
        "\t\t*Hint.* Minimize $$(1/2)x^\\top\\Sigma x - \\sum_{i=1}^n \\rho_i^\\mathrm{des} \\log x_i$$.\n",
        "\t1. Find the investment mix that achieves risk parity for the return covariance matrix $$\\Sigma$$ below.\n",
        "\n",
        "\t```python\n",
        "\timport numpy as np\n",
        "\timport cvxpy as cp\n",
        "\tSigma = np.array(np.matrix(\"\"\"6.1  2.9  -0.8  0.1;\n",
        "\t                     2.9  4.3  -0.3  0.9;\n",
        "\t                    -0.8 -0.3   1.2 -0.7;\n",
        "\t                     0.1  0.9  -0.7  2.3\"\"\"))\n",
        "\trho = np.ones(4)/4\n",
        "\t```\n",
        "\n",
        "4. **💲 📈📉 Как с деньгами обстоит вопрос?** In this task you are to select your own portfolio and formulate your favorite optimization problem to solve it with cvxpy. Take a look at the example, described in the class  [🐍 code](https://colab.research.google.com/github/MerkulovDaniil/sber219/blob/main/notebooks/4_1.ipynb){: .btn}.\n",
        "\n",
        "\t![](https://pbs.twimg.com/media/Ef-YalfXYAAUDaf.jpg)\n",
        "\n",
        "\t```python\n",
        "\t!pip install yfinance --quiet\n",
        "\n",
        "\timport datetime\n",
        "\timport matplotlib.pyplot as plt\n",
        "\timport pandas\n",
        "\timport numpy as np\n",
        "\tfrom pandas_datareader import data as pdr\n",
        "\timport yfinance as yfin\n",
        "\tyfin.pdr_override()\n",
        "\n",
        "\t### YOUR STOCKS HERE\n",
        "\t#stocks = ['GOOGL', 'SPY', 'AAPL', 'TSLA', 'MSFT']\n",
        "\tstocks = []\n",
        "\tdf = pdr.get_data_yahoo(stocks, start=\"2021-01-01\")\n",
        "\n",
        "\t# Adjusted price\n",
        "\tfor stock in stocks:\n",
        "\t    plt.plot(df['Adj Close'][stock], label=stock)\n",
        "\tplt.xlabel('date')\n",
        "\tplt.ylabel('Adjusted price')\n",
        "\tplt.legend()\n",
        "\tplt.show()\n",
        "\n",
        "\t# Fractional return\n",
        "\tfrac_return = {}\n",
        "\tfor stock in stocks:\n",
        "\t    frac_return[stock] = [(price - df['Adj Close'][stock][0])/df['Adj Close'][stock][0] for price in df['Adj Close'][stock]]\n",
        "\t    plt.plot(frac_return[stock], label=stock)\n",
        "\tplt.xlabel('date')\n",
        "\tplt.ylabel('Fractional return')\n",
        "\tplt.legend()\n",
        "\tplt.show()\n",
        "\t```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAemAqvjevq1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}