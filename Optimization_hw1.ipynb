{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optimization_hw1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7Na4_2_Ii2i"
      },
      "source": [
        "# Homework №1. Astanova Kamilla #\n",
        "## Matrix calculus ##\n",
        "\n",
        "### 1. Find $\\nabla f(x)$, if $f(x) = \\dfrac{1}{2} \\| Ax - b\\|^2_2$, $x \\in \\mathbb{R}^p$\n",
        "#### Решение ####\n",
        "Начнем с разбора нормы:\n",
        "\n",
        "$$ \\| x \\|_2 = \\sqrt{\\sum\\limits^p_{i=1} |x_i|^2 } \\hspace{0.8cm} \\Rightarrow \\hspace{0.8cm} \\|x\\|^2_2 = x^Tx =  \\, \\langle x, x\\rangle$$\n",
        "\n",
        "Пользуясь свойством $\\mathrm{d} f(x) = \\langle \\nabla f(x), \\mathrm{d}x\\rangle$, вычислим сначала $\\mathrm{d}f(x)$:\n",
        "\n",
        "$$ \\mathrm{d}\\left(\\dfrac{1}{2}\\langle Ax - b, Ax - b \\rangle \\right) = \\dfrac{2}{2} \\langle Ax - b, A\\mathrm{d}x\\rangle = \\langle A^T(Ax - b), \\mathrm{d}x\\rangle$$\n",
        "\n",
        "Откуда получаем $$ \\nabla f(x) = A^TAx - A^Tb $$\n",
        "\n",
        "\n",
        "### 2. Find $\\nabla f(x)$, if $f(x) = \\langle x, x\\rangle^{\\langle x, x\\rangle},\\, x \\in R^n\\backslash\\{0\\}$\n",
        "#### Решение  ####\n",
        "Вспомним, что производная $g(x)^{h(x)}$ это производная степенной + производная показательной, т.е.:\n",
        "\n",
        "$$ \\mathrm{d}(g(x)^{h(x)}) = g(x)^{h(x)-1}h(x)\\mathrm{d}g(x) + g(x)^{h(x)}\\ln{g(x)}\\mathrm{d}h(x) $$\n",
        "\n",
        "С учетом $ g(x) = h(x) = \\langle x,x\\rangle$ и $\\mathrm{d}g(x) = \\mathrm{d}h(x) = 2\\langle x, \\mathrm{d}x\\rangle$, получаем:\n",
        "\n",
        "$$ \\langle x, x\\rangle^{\\langle x, x\\rangle} \\left(\\dfrac{\\langle x, x\\rangle}{\\langle x, x\\rangle}2\\langle x, \\mathrm{d}x\\rangle + \\ln{\\langle x,x\\rangle}2\\langle x, \\mathrm{d}x\\rangle \\right) = \\left\\langle \\langle x, x\\rangle^{\\langle x, x\\rangle}2x\\left( \\ln{\\langle x,x\\rangle} + 1\\right) , \\mathrm{d}x\\right\\rangle$$\n",
        "\n",
        "Откуда $$ \\nabla f(x) = 2 \\langle x, x\\rangle^{\\langle x, x\\rangle}\\left( \\ln{\\langle x,x\\rangle} + 1\\right) x$$\n",
        "\n",
        "\n",
        "### 3. Calculate the Frobenious norm derivative: $ \\dfrac{\\partial}{\\partial X}\\|X\\|^2_F$\n",
        "#### Решение  ####\n",
        "Распишем норму Фробениуса:\n",
        "\n",
        "$$ \\| X\\|_F : \\mathbb{R}^{m\\times n} \\rightarrow \\mathbb{R}$$\n",
        "\n",
        "$$ \\| X\\|_F = \\sqrt{\\sum\\limits^{m}_{i=1} \\sum\\limits^{n}_{j=1}|x_{ij}|^2}$$\n",
        "\n",
        "Поэтому в результате взятия производной у нас получится матрица $m \\times n$, у которой в каждой $kl$-той ячейке будет лежать производная $\\dfrac{\\partial f(X)}{\\partial x_{kl}}$, где $f(X) = \\| X\\|_F^2$. Вычислим содержимое $kl$-той ячейки:\n",
        "\n",
        "$$ \\dfrac{\\partial f(X)}{\\partial x_{kl}} = \\dfrac{\\partial}{\\partial x_{kl}}\\left(\\sum\\limits^{m}_{i=1} \\sum\\limits^{n}_{j=1}|x_{ij}|^2 \\right) =\\dfrac{\\partial |x_{kl}|^2}{\\partial x_{kl}} = 2|x_{kl}|\\text{sign}x_{kl} = 2x_{kl}$$\n",
        "\n",
        "Если в каждой $kl$-той ячейке лежит $2x_{kl}$, то результат:\n",
        "\n",
        "$$  \\dfrac{\\partial}{\\partial X}\\|X\\|^2_F = 2X$$\n",
        "\n",
        "### 4. Calculate the first and the second derivative of the following function $f: S \\rightarrow \\mathbb{R}$, $f(t) = \\det(A - tI_n)$, where $ A \\in \\mathbb{R}^{n\\times n}, \\, S:= \\{t\\in \\mathbb{R} : \\det(A- tI_n) \\neq 0\\}$\n",
        "#### Решение ####\n",
        "$A-tI_n = T \\Rightarrow \\mathrm{d} \\det T = \\det T\\langle T^{-T}, \\mathrm{d}T\\rangle $\n",
        "\n",
        "$\\mathrm{d}T = -I_n\\mathrm{d}t \\Rightarrow \\mathrm{d} \\det T =\\langle -\\det T\\times T^{-T}, \\mathrm{d}t\\rangle = g(t) = f'(t)$\n",
        "\n",
        "$\\mathrm{d}g(t) = \\mathrm{d}\\langle -\\det T\\times T^{-T}, \\mathrm{d}t_1\\rangle = \\langle \\langle \\det T\\times T^{-T}, \\mathrm{d}t\\rangle\\times T^{-T} - \\det T\\times (T^{-1}(\\mathrm{d}T)T^{-1})^T, \\mathrm{d}t\\rangle$\n",
        "\n",
        "### 5. Implement analytical expression of the gradient and hessian of the following functions: a.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6yrmFC9JUew"
      },
      "source": [
        "## Convex sets ##\n",
        "\n",
        "### 1. Prove that the set of square symmetric positive definite matrices is convex.\n",
        "\n",
        "#### Решение ####\n",
        "Распишем, что по определению означает, что матрица строго положительно определена: \n",
        "\n",
        "$$A \\in \\mathbb{R}^{n\\times n}_{++} \\hspace{0.8cm} \\Rightarrow \\hspace{0.8cm} \\forall x \\neq 0: x^TAx>0$$\n",
        "\n",
        "Теперь рассмотрим $A, B \\in \\mathbb{R}^{n\\times n}_{++}$ и $C = \\theta A + (1-\\theta)B, \\, \\theta \\in [0; 1]$. Теперь для $\\forall x\\neq0$:\n",
        "\n",
        "$$ x^TCx = x^T\\left(\\theta A + (1-\\theta)B\\right)x = \\theta x^TAx + (1-\\theta)x^TBx$$\n",
        "Последний переход был сделан по свойству дистрибутивности умножения матриц относительно сложения. \n",
        "\n",
        "Теперь учитываем, что $x^TAx>0$ и $x^TBx>0$, а из двух чисел $\\theta$ и $(1-\\theta)$ как минимум одно всегда строго больше нуля (либо они больше нуля оба, либо в случаях на концах отрезка $[0;1]$ одно из них зануляется). Поэтому сумма в правой части всегда $>0$ при $x \\neq 0$, что по определению означает, что $C \\in \\mathbb{R}^{n\\times n}_{++}$, а это, в свою очередь, означает, что множество квадратных положительно определенных матриц выпукло $\\rightarrow$ ч.т.д..\n",
        "\n",
        "### 2. Show that $\\textbf{conv}\\{xx^T: \\, x\\in\\mathbb{R}^n, \\|x\\| = 1\\} = \\{A\\in \\mathbb{S}^n_+: \\, \\text{tr}(A) = 1\\}$\n",
        "\n",
        "### Решение ###\n",
        "\n",
        "Аккуратно все рассмотрим:\n",
        "1. Покажем, что $A$ будут получаться симметрическими. Очевидно, что матрица, получающаяся от $xx^T$ будет симметрической, т.к. в каждой $ij$-той ячейке будет лежать $x_ix_j$, поэтому $a_{ij} = a_{ji}$. Введем верхний индекс $k$ для обозначения разных векторов, на которых будут строится матрицы $x^k(x^k)^T$ и рассмотрим выпуклую оболочку:\n",
        "$$ \\textbf{conv}\\{xx^T\\} = \\left\\{A = \\sum\\limits_{k=1}^m \\theta_k x^k(x^k)^T \\, \\Big| \\, x^k \\in \\mathbb{R}^n, \\sum\\limits_{k=1}^m \\theta_k = 1, \\theta_k \\geq 0 \\right\\}$$\n",
        "  т.е. справедливо $a_{ij} = \\sum\\limits_{k=1}^m \\theta_k x_i^kx_j^k = \\sum\\limits_{k=1}^m \\theta_k x_j^kx_i^k = a_{ji}$, откуда следует $A \\in \\mathbb{S}^n$\n",
        "\n",
        "2. Теперь покажем, что эти матрицы будут еще и положительно полуопределены. Для этого снова сначала рассмотрим определенность матрицы $xx^T$:\n",
        "$$\\forall b\\neq 0\\in \\mathbb{R}^n: \\hspace{0.5cm}  b^Txx^Tb = (x^Tb)^T(x^Tb) = c*c = c^2 \\geq 0$$\n",
        "т.к. $x^Tb$ это результат скалярного произведения - число $c = \\sum\\limits_{i=1}^n x_ib_i$. Теперь рассмотрим $b^TAb$. Используя свойство дистрибутивности, как в предыдущем номере, получаем:\n",
        "$$ b^TAb = \\sum\\limits_{k=1}^m \\theta_k b^Tx^k(x^k)^Tb, \\, \\text{где} \\ \\forall k: \\ b^Tx^k(x^k)^Tb \\geq 0 \\ \\text{и} \\ \\theta_k \\geq 0 \\rightarrow b^TAb \\geq 0$$\n",
        " По определению $A \\in \\mathbb{S}^n_+$.\n",
        "\n",
        "3. Осталось доказать, что $\\text{tr}(A) = 1$. След матрицы это сумма диагональных элементов: $\\text{tr}(A) = \\sum\\limits_{i=1}^n a_{ii}$. Для матрицы $xx^T$: \n",
        "$$ \\text{tr}(xx^T) = \\sum\\limits_{i=1}^n x_i^2 = \\|x\\|^2 = 1$$\n",
        "Откуда\n",
        "$$ \\text{tr}(A) = \\sum\\limits_{i=1}^n \\sum\\limits_{k=1}^m \\theta_k(x^k_i)^2 = \\sum\\limits_{k=1}^m \\theta_k \\text{tr}(x^k(x^k)^T) = \\sum\\limits_{k=1}^m \\theta_k * 1 = 1 $$\n",
        "Ч.т.д.. ну это я доказала вложение только в одну сторону... обратно как хз \n",
        "\n",
        "### 3. Show that the hyperbolic set of $\\{ x \\in \\mathbb{R}^n_+ | \\prod\\limits^n_{i=1}x_i \\geq 1 \\}$ is convex. Hint: For $0 \\leq \\theta \\leq 1$ it is valid, that $a^\\theta b^{1-\\theta} \\leq \\theta a +(1-\\theta)b$ with non-negative $a, b$.\n",
        "\n",
        "#### Решение #### \n",
        "Расписываем по определению и пользуемся подсказкой (подсказкой можем воспользоваться т.к. $x, y \\in \\mathbb{R}^n_+$ и $0 \\leq \\theta \\leq 1$):\n",
        "$$ z = \\theta x + (1-\\theta)y $$\n",
        "$$ \\prod\\limits^n_{i=1}z_i = \\prod\\limits^n_{i=1}(\\theta x_i + (1-\\theta)y_i) \\geq \\prod\\limits^n_{i=1} x_i^\\theta y_i^{1-\\theta} = \\left(\\prod\\limits^n_{i=1} x_i\\right)^\\theta \\times \\left(\\prod\\limits^n_{i=1}y_i\\right)^{1-\\theta} \\geq 1^\\theta \\times 1^{1-\\theta} = 1$$\n",
        "Откуда следует, что $z$ тоже принадлежит этому множеству, а значит, оно выпукло.\n",
        "\n",
        "### 4. Prove, that the set $S \\subseteq \\mathbb{R}^n$ is convex if and only if $(\\alpha + \\beta)S = \\alpha S + \\beta S$ for all non-negative $\\alpha$ and $\\beta$\n",
        "\n",
        "#### Решение ####\n",
        "1. Из равенства почти сразу следует выпуклость. Положим $\\alpha = \\theta$ и $\\beta = 1-\\theta$. Тогда $\\theta S + (1-\\theta)S = (\\theta + 1 - \\theta)S = S$, т.е. $\\theta x + (1-\\theta)y \\in S \\rightarrow$ ч.т.д..\n",
        "2. Из выпуклости докажем равенство. Докажем включение в обе стороны $ (\\alpha + \\beta)S \\subseteq \\alpha S + \\beta S$  и $(\\alpha + \\beta)S \\supseteq \\alpha S + \\beta S$.\n",
        "  + Первое включение очевидно из равенства $(\\alpha + \\beta)x = z =\\alpha x + \\beta x$, т.е. $z \\in (\\alpha + \\beta)S \\Rightarrow z \\in \\alpha S + \\beta S$.\n",
        "  + Второе включение: пусть $z = \\alpha x + \\beta y \\in \\alpha S + \\beta S$. Тогда \n",
        "  $$ z = (\\alpha + \\beta) \\left(\\dfrac{\\alpha}{\\alpha + \\beta}x + \\dfrac{\\beta}{\\alpha + \\beta}y\\right) = (\\alpha + \\beta) \\left(\\theta x + (1-\\theta)y\\right) = (\\alpha + \\beta) r$$\n",
        "где $r \\in S \\Rightarrow я \\in (\\alpha + \\beta)S$\n",
        "\n",
        "  Из двух включений следует равенство $(\\alpha + \\beta)S = \\alpha S + \\beta S$ - ч.т.д..\n",
        "\n",
        "### 5. Let $x\\in \\mathbb{R}$ is a random variable with a given probability distribution of $\\mathbb{P}(x=a_i) = p_i$, where $i = 1, \\cdots, n$, and $a_1 < \\cdots < a_n$. It is said that the probability vector of outcomes of $p\\in \\mathbb{R}^n$ belongs to the probabilistic simplex, i.e. $P = \\{ p | 1^Tp = 1, p \\succeq 0\\} = \\{p| p_1+\\cdots+p_n = 1, p_i \\geq 0\\}$. Determine if the following sets of $p$ are convex:\n",
        "+ $\\mathbb{P}(x>\\alpha) \\leq \\beta$\n",
        "####Решение ####\n",
        "+ $\\mathbb{E}|x^{201}| = \\alpha \\mathbb{E}|x|$\n",
        "####Решение ####\n",
        "+$\\mathbb{E}|x^{2}| \\leq \\alpha$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4sCi0XSAWvw"
      },
      "source": [
        "## Convex functions ##\n",
        "\n",
        "### 1. Prove, that function $f(X) = \\text{tr}(X^{-1}), \\, X \\in S^n_{++}$ is convex, while $g(X) = \\det(X)^{1/n}, \\, X \\in S^n_{++}$ is concave.\n",
        "#### Решение ####\n",
        "\n",
        "\n",
        "### 2. Слишком длинное условие\n",
        "#### Решение ####\n",
        "$x\\ln x$ выпукла на $\\mathbb{R}_{++}$. А у нас $f(p)$ сумма выпуклых по каждой координате функций, значит, вся $f(p)$ выпукла (потому что если расписывать неравенство для всего $f(p)$, то каждое слагаемое в этой сумме будет будет удовлетворять неравенству для своей координаты). Поэтому мы можем записать неравенство:\n",
        "$$ f(p) \\geq  f(q) + \\nabla f(q)^T(p-q) \\Rightarrow D(p,q) = f(p) - f(q) - \\nabla f(q)^T(p-q) \\geq 0 $$\n",
        "Если $D(p,q) = 0$, то $f(p) = f(q)$ и $\\nabla f(q)^T = 0$, но это может быть только в случае $p=q$ (т.к. $f(p) \\not\\equiv const$). \n",
        "\n",
        "### 4. слишком длинное условие\n",
        "#### Решение ####\n",
        "Здесь гессиан для $a(x)$ будет нулевой матрицей, т.к. все члены входят линейно и вторые производные уже будут от констант, т.е. равны нулю, поэтому это выпуклая функция.\n",
        "\n",
        "### 5. Is $f(x) = -x\\ln x -(1-x)\\ln(1-x)$ convex?\n",
        "####Решение ####\n",
        "Я опущу вычисление производных и сразу выпишу:\n",
        "$$ f''(x) = -\\dfrac{1}{x(1-x)}$$\n",
        "С учетом $x>0; \\ 1-x > 0$ как аргументы логарифма, получаем, что $f''(x) <0$ - $f(x)$ не выпуклая.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOcyOq6ZAXKH"
      },
      "source": [
        "## Conjugate sets\n",
        "\n",
        "### 1. Let $\\mathbb{A}_n$ be the set of all $n$ dimensional antisymmetric matrices. Show that $(\\mathbb{A}_n)^* = \\mathbb{S}_n$\n",
        "\n",
        "#### Решение ####\n",
        "\n",
        "Докажем включение $\\mathbb{S}_n \\subseteq (\\mathbb{A}_n)^*$. Пусть $A$ - кососимметрическая матрица, а $S$ - симметрическая. Распишем \n",
        "$$\\langle A, S\\rangle = \\text{tr}(A^T\\times S) = \\text{tr}(-A\\times S) = -\\sum\\limits_{i=1}^n \\left(\\sum\\limits_{j=1}^n a_{ij}s_{ji}\\right)$$\n",
        "\n",
        "$$\\langle A, S\\rangle = \\text{tr}(S^T\\times A) = \\text{tr}(S\\times A) = \\sum\\limits_{i=1}^n \\left(\\sum\\limits_{j=1}^n s_{ij}a_{ji}\\right) = \\sum\\limits_{j=1}^n \\left(\\sum\\limits_{i=1}^n a_{ji}s_{ij}\\right)$$\n",
        "\n",
        "$$-\\sum\\limits_{i=1}^n \\left(\\sum\\limits_{j=1}^n a_{ij}s_{ji}\\right) = \\sum\\limits_{j=1}^n \\left(\\sum\\limits_{i=1}^n a_{ji}s_{ij}\\right) \\Rightarrow \\sum\\limits_{i=1}^n \\left(\\sum\\limits_{j=1}^n a_{ij}s_{ji}\\right) = 0 \\geq -1$$\n",
        "Откуда следует, что если $S \\in \\mathbb{S}_n$, то $S \\in (\\mathbb{A}_n)^*$. Получаем включение $\\mathbb{S}_n \\subseteq (\\mathbb{A}_n)^*$.\n",
        "\n",
        "Теперь докажем обратное включение $(\\mathbb{A}_n)^* \\subseteq \\mathbb{S}_n$. Пусть есть какая-то $S$, про которую мы еще не знаем, что она симметрическая, но знаем, что $\\mathbb{S}_n \\subseteq (\\mathbb{A}_n)^*$. Мы выше показали, что если бы $S$ была симметрической, то $\\langle A, S\\rangle = 0$. Теперь нужно посмотреть, может ли быть у матрицы $S$ без каких либо ограничений $\\langle A, S\\rangle \\neq 0$. \n",
        "$$ -\\sum\\limits_{i=1}^n \\left(\\sum\\limits_{j=1}^n a_{ij}s_{ji}\\right) \\neq 0$$\n",
        "$$ \\sum\\limits_{i=1}^n \\left(\\sum\\limits_{j=1}^n a_{ij}s_{ji}\\right) = \\sum\\limits_{i=1}^n\\sum\\limits_{j=1}^ia_{ij}(s_{ji}-s_{ij})$$\n",
        "В последнем равенстве мы использовали $a_{ij} = -a_{ji}$, откуда следует, что можно использовать коэффициенты только из нижней части (кусок матрицы $A$ представляющий собой нижнюю треугольную матрицу), поэтому у части слагаемых у суммы мы поменяли эти коэффициенты и вынесли за скобки. Тогда, если эта сумма это линейная комбинация, в которой $a_{ij}$ могут быть любыми (потому что все $a_{ji}$ мы уже заменили) и в силу произвольности выбора $a_{ij}$, чтобы суммма линейной комбинации не стала $<-1$, каждая из скобок $(s_{ji}-s_{ij})$ должна быть равна нулю, а значит $s_{ji}=s_{ij}$, т.е. $S \\in \\mathbb{S}_n$. Из двух включений следует ч.т.д..\n",
        "\n",
        "### 2. Find the conjugate set to the ellipsoid: $$ S = \\left\\{x \\in \\mathbb{R}^n \\Big| \\sum\\limits_{i=1}^n a_i^2x_i^2 \\leq \\varepsilon^2\\right\\}$$\n",
        "\n",
        "#### Решение ####\n",
        "Перепишем эллипсоид в виде \n",
        "\n",
        "$$ \\sum\\limits_{i=1}^n \\left(\\dfrac{a_i}{\\varepsilon}\\right)^2x_i^2 \\leq 1$$\n",
        "\n",
        "Тогда это будет круг с изначальным радиусом $1$, но который растянули с коэффициентами $\\dfrac{\\varepsilon}{a_i}$. Тогда аналогично тому, как мы в одномере подпирали шарик в одномере, будем здесь подпирать эллипсоид. Рассмотрим какую-то точку эллипсода $x_0$. Множество, которое ей будет сопряжено - это полуплоскость, которая отделяется прямой $x_0^Tx = -1$ и берется та полуплоскость, в которой лежит сама $x_0$. Тогда эта прямая будет все ближе к началу координат по мере роста $\\|x_0\\|$. Если проделать все это в двумере, то становится понятно, что получится эллипсоид с обратными коэффициентами сжатия $\\dfrac{a_i}{\\varepsilon}$. Т.е.\n",
        "$$ S^* = \\left\\{y \\in \\mathbb{R}^n \\Big| \\sum\\limits_{i=1}^n \\left(\\dfrac{\\varepsilon}{a_i}\\right)^2y_i^2 \\leq 1\\right\\}$$\n",
        "\n",
        "![picture](https://drive.google.com/file/d/1Y06BPXhmJ_Gng9vr8Xgv1CQKzixPoBFF/view?usp=sharing)\n",
        "\n",
        "### 3. Find the sets $S^{*}, S^{**}, S^{***}$, if $$S = \\{x \\in \\mathbb{R}^2 | x_1 + x_2 \\geq -1, 2x_1 + x_2 \\geq 1, -2x_1 + x_2 \\geq 2$$\n",
        "\n",
        "#### Решение ####\n",
        "Нашла область, которая ограничивается данными неравенствами. Получилось, что это конус на образующих $A=(1;2)^T$ и $B=(-1;2)^T$ и сдвинутый относительно начала координат в точку $C =\\left(-\\dfrac{1}{4}; \\dfrac{1}{2}\\right)^T$. Т.е. мы представили $S = \\textbf{conv}(C) +\\textbf{cone}(A; B) = C + \\textbf{cone}(A; B)$. Тогда по теореме:\n",
        "$$ S^* = \\{x \\in \\mathbb{R}^2 | x_1 \\left(-\\dfrac{1}{4}\\right) + x_2\\dfrac{3}{2} \\geq -1, x_1 + 2x_2 \\geq 0, -x_1 + 2x_2 \\geq 0 \\}$$\n",
        "\n",
        "И в результате $S^*$ получился просто конус с образующими $A = (2; 1)^T$ и $B = (-2; 1)^T$ и выходящий из начала координат.\n",
        "Поэтому, когда мы будем строить $S^{**}$, то это будет конус с образующими $(1;2)^T$ и $(-1;2)^T$, тоже выходящий из начала координат.  А $S^{***} = S^{*}$ в свою очередь. \n",
        "\n",
        "## 5. Prove, that $B_p$ and $B_{p_*}$ are inter-conjugate, i.e. $(B_p)^* = B_{p_*}$, $(B_{p_*})^* = B_{p}$, where $B_p$ is the unit ball (w.r.t. $p$ - norm) and $p,p_∗$ are conjugated, i.e. $p^{-1} +p_*^{-1}=1$. You can assume, that $p_* = \\infty$, if $p=1$ and vice versa.##\n",
        "### Решение ###\n",
        "Первое вложение $(B_p)^* \\subseteq B_{p_*}$. $y\\in (B_p)^*$. Нужно доказать, что $y \\in B_{p_*}$. Воспользуемся аналогом КБШ для сопряженных норм:\n",
        "$$ |y^Tx| \\leq \\|x\\|\\|y\\|_*$$\n",
        "Т.к. $\\forall x\\in B_p: \\ y^Tx \\geq -1$, то слева произведение норм подпиралось бы -1, значит, и справа должно подпираться 1 (мы такой ход на сеинаре делали). Тогда (сразу учитываем, что $B_p$ - единичный шар с нормой $p$, т.е. $\\|x\\| \\leq 1$):\n",
        "$$ \\|x\\|\\|y\\|_* \\leq \\|y\\|_*\\leq 1 $$\n",
        "Т.е. $y \\in B_{p_*} \\Rightarrow (B_p)^* \\subseteq B_{p_*}$\n",
        "\n",
        "В обратную сторону. Пусть $y \\in B_{p_*}$ ($\\|x\\|\\leq 1, \\ \\|y\\|_*\\leq 1$).\n",
        "$$ |y^Tx| \\leq \\|x\\|\\|y\\|_* \\leq 1*1 \\Rightarrow -1\\leq y^Tx \\leq 1$$ \n",
        "Т.е. $y^Tx \\geq -1 \\Rightarrow y\\in (B_p)^* \\Rightarrow B_{p_*} \\subseteq (B_{p})^* \\Rightarrow (B_p)^* = B_{p_*}$ ч.т.д..\n",
        " Аналогично вторую пару рассмотреть."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4cnC643AYmI"
      },
      "source": [
        "## Conjugate function ##\n",
        "### 1. Find $f^*(y)$, if $f(x) = -\\dfrac{1}{x}, x \\in \\mathbb{R}_{++}$\n",
        "#### Решение ####\n",
        "$f(x)$ дифференцируема на области $\\mathbb{R}_{++}$. Тогда можем рассмотреть производную выражения под супремумом:\n",
        "$$(yx - f(x))'_x = y - \\dfrac{1}{x^2}$$\n",
        "Супремум $\\sup\\limits_{x\\in\\text{dom}f}\\left(yx + \\dfrac{1}{x}\\right)$ тогда будет достигаться в $\\widetilde{x} = \\dfrac{1}{\\sqrt{y}}$, откуда следует, что область определения $f^*(y):$ $y>0$. Подставляем $\\widetilde{x}$\n",
        "$$ f^*(y) = y\\widetilde{x} - f(\\widetilde{x}) = y\\dfrac{1}{\\sqrt{y}} + \\sqrt{y} = 2\\sqrt{y}$$\n",
        "$$f^*(y) = 2\\sqrt{y}, \\ \\ y>0$$\n",
        "\n",
        "### 2. Profe, that if $f(x_1, x_2) = g_1(x_1) + g_2(x_2) $, then $f^*(y_1, y_2) = g_1^*(y_1) + g^*_2(y_2)$\n",
        "\n",
        "#### Решение ####\n",
        "Распишем определение: \n",
        "$$f^*(y_1, y_2) = \\sup\\limits_{x\\in\\text{dom}f}(\\langle y, x\\rangle - f(x_1, x_2)) =  \\sup\\limits_{x\\in\\text{dom}f}(y_1x_1+y_2x_2 - g_1(x_1) - g_2(x_2)) = \\sup\\limits_{x\\in\\text{dom}f}(y_1x_1 - g_1(x_1)) + \\sup\\limits_{x\\in\\text{dom}f}(y_2x_2 - g_2(x_2)) = g_1^*(y_1) + g^*_2(y_2)$$\n",
        "Переход к двум супремумам мы могли сделать, потому что они зависят от разных наборов переменных.\n",
        "\n",
        "### 3. Find $f^*(y)$, if $f(x) = \\log{\\left( \\sum\\limits_{i=1}^ne^{x_i}\\right)}$\n",
        "#### Решение ####\n",
        "Принцип такой же, как в 3 задаче, только для многомерного случая, т.е. аналог производной - градиент. А можем мы здесь находить его, т.к. $f(x)$ дифференцируемая функция на всей области (под логарифмом всегда положительное значение)\n",
        "$$ \\nabla (y^Tx -f(x))$$\n",
        "Для каждой $i$-той компоненты тогда будет:\n",
        "$$ y_i - \\dfrac{e^{x_i}}{\\sum\\limits_{i=1}^ne^{x_i}} = 0$$\n",
        "А дальше можно составить СЛАУ относительно $e^{x_i}$, а дальше хк как ее решать не придумала\n",
        "\n",
        "### 4. Profe, that if $f(x) = \\alpha g(x)$, then $f^*(y) = \\alpha g^*(y/\\alpha)$\n",
        "#### Решение #### \n",
        "Распишем определение (т.к. у нас в аргументе функции $g$ делят на $\\alpha$, то я сразу полагаю, что $\\alpha \\neq 0$):\n",
        "\n",
        "$$ f^*(y) = \\sup\\limits_{x\\in\\text{dom}f}(y^Tx - f(x)) = \\sup\\limits_{x\\in\\text{dom}f}(\\alpha \\dfrac{1}{\\alpha}y^Tx - \\alpha g(x)) = \\alpha \\sup\\limits_{x\\in\\text{dom}f}(\\dfrac{1}{\\alpha}y^Tx - g(x)) = \\alpha g^*(y/\\alpha)$$\n",
        "Т.е. в конце просто каждая компонента исходного $y$ в $\\alpha$ раз меньше, поэтому пишем $g^*(y/\\alpha)$. \n",
        "\n",
        "\n",
        "### 5. Find $f^*(Y)$, if $f(X) = -\\ln\\det X, X\\in \\mathbb{S}^n_{++}$\n",
        "#### Решение ####\n",
        "Распишем по определению с учетом, что $X\\in \\mathbb{S}^n_{++} \\Rightarrow \\det X>0 \\Rightarrow f(X) $ дифференцируема на области определения.\n",
        "$$ f^*(Y) = \\sup\\limits_{X\\in\\text{dom}f}(\\langle Y, X\\rangle +\\ln\\det X)$$\n",
        "$$ g(X, Y) =  \\langle Y, X\\rangle +\\ln\\det X$$\n",
        "$$ \\partial g(X, Y) = \\langle Y, \\mathrm{d}X\\rangle -\\dfrac{\\det X\\langle X^{-T}, \\mathrm{d}X\\rangle}{\\det X} = \\langle Y - X^{-T}, \\mathrm{d}X\\rangle = 0$$\n",
        "т.е.\n",
        "$$ \\widetilde{X} = Y^{-T}$$\n",
        "Разберемся, какого вида тогда будут $Y$ из области определения. Если $X \\in \\mathbb{S}^n_{++}$, то $Y^{-T} \\in \\mathbb{S}^n_{++}$, а т.к. обратная к симметрической пложительно определенной матрице - симметрическая ($XX^{-1} = E = X^T(X^{-1})^T$ ) и положительно определенная матрица ($x = A^{-1}y \\Rightarrow x^TAx = y^TA^{-T}AA^{-1}y = y^TA^{-T}y >0$), то и $Y \\in \\mathbb{S}^n_{++}$. А значит, осталось подставить $\\widetilde{X}$:\n",
        "\n",
        "$$ f^*(Y) = g(\\widetilde{X}, Y) = \\langle Y, Y^{-T}\\rangle +\\ln\\det Y^{-T} = \\text{tr}(Y^{-1}Y) + \\ln\\det Y^{-1} = n + \\ln\\det Y^{-1}$$\n",
        "$$ f^*(Y) = n + \\ln\\det Y^{-1}, \\ \\ Y \\in \\mathbb{S}^n_{++}$$\n",
        "\n",
        "### 6. Prove, that if $f(x) = \\inf\\limits_{u+x=x}(g(u)+h(v))$, then $f^*(y) = g^*(u)+h^*(v)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGd1ewTiAYsa"
      },
      "source": [
        "## Subgradient and subdifferential ##\n",
        "### 1. Prove, that $x_0$ - is the minimum point of a convex function $f(x_0)$ if and only if $0 \\in \\partial f(x_0)$\n",
        "\n",
        "#### Решение ####\n",
        "+ Пусть $0 \\in \\partial f(x_0)$, тогда по определению \n",
        "$$ f(x) \\geq f(x_0) + \\langle g, x - x_0\\rangle  = f(x_0), \\, \\text{при} \\, g = 0$$\n",
        "Что означает, что $x_0$ точка минимума.\n",
        "\n",
        "+ Аналогично расписываем неравенство в обратную сторону: из минимума имеем $f(x) \\geq f(x_0) = f(x_0) + \\langle g, x - x_0\\rangle \\, \\text{при} \\, g = 0$ - ч.т.д..\n",
        "\n",
        "### 2. Find $\\partial f(x)$, if $f(x) = \\text{ReLU}(x) = \\max\\{0,x\\}$\n",
        "\n",
        "#### Решение ####\n",
        "+ При $x < 0:$  $f(x) \\equiv 0$, поэтому $\\partial f(x) = 0$\n",
        "+ При $x > 0:$  $f(x) = x$, поэтому $\\partial f(x) = 1$\n",
        "+ При $x = 0$ в этой точке две активные функции и по теореме Дубовицкого-Милютина $\\partial f(x) = [0; 1]$\n",
        "\n",
        "### 3. Find $\\partial f(x) = \\|x\\|_p$ при $p = 1, 2, \\infty$\n",
        "\n",
        "#### Решение ####\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Oq0cCQN36uG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}